{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deepbind2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"uosH3ughmaVn","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')\n","# After executing the cell above, Drive\n","# files will be present in \"/content/drive/My Drive\".\n","!ls \"/content/drive/My Drive\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"coXeS8RbmvD_","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls \"/content/drive/My Drive/Colab Notebooks/\"\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UiSAAZ_OkWri","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import csv\n","import math \n","import random\n","import gzip\n","from scipy.stats import bernoulli"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jASRrXw4kWrn","colab_type":"code","colab":{}},"cell_type":"code","source":["nummotif=16 #number of motifs to discover\n","bases='ACGT' #DNA bases\n","basesRNA='ACGU'#RNA bases\n","batch_size=64 #fixed batch size -> see notes to problem about it\n","dictReverse={'A':'T','C':'G','G':'C','T':'A','N':'N'} #dictionary to implement reverse-complement mode"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iWEt7WVVkWrp","colab_type":"code","colab":{}},"cell_type":"code","source":["class Experiment:\n","    def __init__(self,filename,motiflen):\n","        self.file=filename\n","        self.motiflen=motiflen\n","    \n","    def getMotifLen(self):\n","        return self.motiflen"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jhp-yVajkWrs","colab_type":"code","colab":{}},"cell_type":"code","source":["def seqtopad(sequence,motlen,kind='DNA'):\n","    rows=len(sequence)+2*motlen-2\n","    S=np.empty([rows,4])\n","    base= bases if kind=='DNA' else basesRNA\n","    for i in range(rows):\n","        for j in range(4):\n","            if i-motlen+1<len(sequence) and sequence[i-motlen+1]=='N' or i<motlen-1 or i>len(sequence)+motlen-2:\n","                S[i,j]=np.float32(0.25)\n","            elif sequence[i-motlen+1]==base[j]:\n","                S[i,j]=np.float32(1)\n","            else:\n","                S[i,j]=np.float32(0)\n","    return S"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qujC_-HAkWru","colab_type":"code","colab":{}},"cell_type":"code","source":["def dinucshuffle(sequence):\n","    b=[sequence[i:i+2] for i in range(0, len(sequence), 2)]\n","    random.shuffle(b)\n","    d=''.join([str(x) for x in b])\n","    return d\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ju_lj4g8kWrw","colab_type":"code","colab":{}},"cell_type":"code","source":["def logsampler(a,b):\n","#     x=tf.Variable(tf.random_uniform([],minval=0,maxval=1))\n","    x=tf.Variable(tf.random_uniform([],minval=0,maxval=1), trainable=False)\n","    y=10**((math.log10(b)-math.log10(a))*x + math.log10(a))\n","    \n","#     x=np.random.uniform(low=0,high=1)\n","#     y=10**((math.log10(b)-math.log10(a))*x + math.log10(a))\n","    return y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MFBv7OV-kWrz","colab_type":"code","colab":{}},"cell_type":"code","source":["def sqrtsampler(a,b):\n","#     x=tf.Variable(tf.random_uniform([],minval=0,maxval=1))\n","    x=tf.Variable(tf.random_uniform([],minval=0,maxval=1), trainable=False)\n","#     x=np.random.uniform(low=0,high=1)\n","    y=(b-a)*(x**0.5)+a\n","    return y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5NkULJwDkWr1","colab_type":"code","colab":{}},"cell_type":"code","source":["class Chip(Experiment):\n","    def __init__(self,filename,motiflen=24):\n","        self.file = filename\n","        self.motiflen = motiflen\n","            \n","    def openFile(self):\n","        train_dataset=[]\n","     \n","        with gzip.open(self.file, 'rt') as data:\n","            next(data)\n","            reader = csv.reader(data,delimiter='\\t')\n","            \n","            for row in reader:\n","                    train_dataset.append([seqtopad(row[2],self.motiflen),[1]])\n","                    \n","                    train_dataset.append([seqtopad(dinucshuffle(row[2]),self.motiflen),[0]])\n","                   \n","        \n","        \n","        random.shuffle(train_dataset)\n","        frac1=int(len(train_dataset)*1/3)\n","        frac2=int(len(train_dataset)*2/3)\n","        return train_dataset[:frac1],train_dataset[frac1:frac2],train_dataset[frac2:],train_dataset"],"execution_count":0,"outputs":[]},{"metadata":{"id":"a48AQrhKkWr3","colab_type":"code","colab":{}},"cell_type":"code","source":["filename='/content/drive/My Drive/Colab Notebooks/Chip-seq/USF1_HepG2_USF-1_HudsonAlpha_AC.seq.gz'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tByxbfE2kWr6","colab_type":"code","colab":{}},"cell_type":"code","source":["test= Chip(filename)\n","d1,d2,d3,dataAll =test.openFile()\n","\n","data1=np.asarray([el[0] for el in d1],dtype=np.float32)\n","label1=np.asarray([el[1] for el in d1],dtype=np.float32).reshape(len(data1),1)\n","\n","data2=np.asarray([el[0] for el in d2],dtype=np.float32)\n","label2=np.asarray([el[1] for el in d2],dtype=np.float32).reshape(len(data2),1)\n","\n","data3=np.asarray([el[0] for el in d3],dtype=np.float32)\n","label3=np.asarray([el[1] for el in d3],dtype=np.float32).reshape(len(data3),1)\n","\n","data=[data1,data2,data3]\n","label=[label1,label2,label3]\n","\n","data_all=np.asarray([el[0] for el in dataAll],dtype=np.float32)\n","label_all=np.asarray([el[1] for el in dataAll],dtype=np.float32).reshape(len(data_all),1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8Jx0FGiJkWr8","colab_type":"code","colab":{}},"cell_type":"code","source":["def convolution(input_data, num_input_channels, num_filters, filter_shape, conv_weights,bias_weights,wd1,bd1,W,b,pooling,neuType,training,dropprob):\n","\n","    \n","    # setup the convolutional layer operation\n","    out_layer = tf.nn.conv1d(input_data, conv_weights, 1, padding='VALID')\n","\n","    out_layer= tf.subtract(out_layer,conv_bias)\n","\n","    # apply a ReLU non-linear activation\n","    out_layer = tf.nn.relu(out_layer)\n","\n","    # now perform pooling\n","    if pooling == 'max_pool':\n","        pool=tf.reduce_max(out_layer,axis=1) \n","        \n","    elif pooling == 'avg_pool':\n","        out_layer1= tf.reduce_max(out_layer, axis=1)\n","        out_layer2= tf.reduce_mean(out_layer, axis=1)\n","        \n","        x_expanded = tf.expand_dims(out_layer1, 2)                 \n","        y_expanded = tf.expand_dims(out_layer2, 2)  \n","        \n","        concatted = tf.concat([x_expanded, y_expanded], 2)  \n","\n","        pool = tf.reshape(concatted, [-1, 2*num_filters]) \n","        \n","\n","    t =tf.constant(1 ,dtype=tf.float32)\n","    \n","    def ifTrain(pool):\n","        pooldrop = tf.nn.dropout(pool,keep_prob=dropprob)\n","#         pooldrop=tf.multiply(pool,mask) \n","        out = tf.matmul(pooldrop, wd1) + bd1\n","        \n","        return out\n","    def ifTest(pool):\n","        out = dropprob*tf.matmul(pool, wd1) + bd1\n","        return out\n","    \n","    #check if there's hidden stage\n","    if(neuType=='nohidden'):\n","\n","        out = tf.cond(tf.equal(training,t), lambda: ifTrain(pool), lambda: ifTest(pool))\n","\n","        \n","    elif(neuType=='hidden'):\n","\n","\n","        dense_layer1 = tf.matmul(pool, W) + b\n","        dense_layer1=tf.nn.relu(dense_layer1)\n","        \n","        out = tf.cond(tf.equal(training,t), lambda: ifTrain(dense_layer1), lambda: ifTest(dense_layer1))\n","        \n","\n","    return out\n","    \n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"_6AXbP8EkWsA","colab_type":"code","colab":{}},"cell_type":"code","source":["graph=tf.Graph()\n","with graph.as_default():\n","    \n","    num_input_channels=4\n","    num_filters=16\n","    filter_shape=24\n","    pooling='avg_pool'\n","    neuType='nohidden'\n","    \n","    beta1=logsampler(10**-15,10**-3)\n","    beta2=logsampler(10**-10,10**-3)\n","    beta3=logsampler(10**-10,10**-3)\n","\n","    \n","    \n","    learning_rate= logsampler(0.0005, 0.05)\n","    momentum_rate= sqrtsampler(0.95, 0.99)\n","#     momentum_rate=0.5\n","    batch_size=64\n","    with tf.device('/gpu:0'):\n","    \n","      x = tf.placeholder(tf.float32, [None, 147, 4])\n","      y = tf.placeholder(tf.float32,[None,1])\n","      dropprob = tf.placeholder_with_default(1.0, shape=())\n","\n","      # Distinguish training and testing: training=1 for training , =0 for testing\n","      training = tf.placeholder_with_default(1.0, shape=())\n","\n","    with tf.device('/cpu:0'):\n","      \n","      #Set up iterator for the data\n","      dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","      dataset = dataset.shuffle(500).repeat().batch(batch_size)\n","      \n","                  \n","      iterator = dataset.make_initializable_iterator()\n","      data_X, data_y = iterator.get_next()      \n","      data_y = tf.cast(data_y, tf.float32)\n","      \n","      \n","#       training_init_op = iterator.make_initializer(dataset)\n","#       validation_init_op = iterator.make_initializer(dataset_val)\n","      \n","   \n","    with tf.device('/gpu:0'):\n","      \n","      conv_filt_shape = [filter_shape, num_input_channels, num_filters]\n","\n","      stdConv=logsampler(10**-7,10**-3) \n","      # initialise weights and bias for the filter\n","      conv_weights = tf.Variable(tf.truncated_normal(conv_filt_shape, mean=0,stddev=stdConv), name='Conv1_W')\n","      conv_bias = tf.Variable(tf.truncated_normal([num_filters]), name='Conv1_b')\n","\n","\n","\n","      if pooling=='max_pool':\n","          W = tf.Variable(tf.truncated_normal([16,32], mean=0, stddev=0.3), name='W')\n","          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')\n","      else:\n","          W = tf.Variable(tf.truncated_normal([32,32], mean=0, stddev=0.3), name='W')\n","          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')     \n","\n","      if neuType == 'nohidden':\n","          if pooling=='max_pool':\n","              wdim1=16\n","          else:\n","              wdim1=32\n","      else:\n","          wdim1=32\n","      stdNeu=logsampler(10**-5,10**-2) \n","      wd1 = tf.Variable(tf.truncated_normal([wdim1,1], mean=0, stddev=stdNeu), name='w2')\n","      bd1 = tf.Variable(tf.truncated_normal([1], mean=0, stddev=stdNeu), name='b2')\n","\n","\n","      xconv = convolution(data_X,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n","\n","#       sig=xconv\n","      sig = tf.nn.sigmoid(xconv)\n","  \n","      if neuType == 'hidden':\n","        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)+ beta3*tf.norm(W,ord=1)\n","      else:\n","        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)\n","\n","      #optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n","      optimizer=tf.train.MomentumOptimizer(learning_rate,momentum_rate,use_nesterov=True).minimize(loss)\n","\n","    with tf.device('/cpu:0'):\n","      #Set up iterator for the validation data\n","      dataset_val = tf.data.Dataset.from_tensor_slices((x, y))\n","      dataset_val = dataset_val.batch(tf.cast(tf.size(y),tf.int64))\n","                  \n","      iterator_val = dataset_val.make_initializable_iterator()\n","      data_XV, data_yV = iterator_val.get_next()      \n","      data_yV = tf.cast(data_yV, tf.float32)\n","    with tf.device('/gpu:0'):\n","      xconvV = convolution(data_XV,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n","\n","      sigV = tf.nn.sigmoid(xconvV)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yY9abt5qkWsB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":4718},"outputId":"d56b76d5-34d9-4048-b7fb-f5cb55b31f13","executionInfo":{"status":"error","timestamp":1539308696709,"user_tz":360,"elapsed":2838442,"user":{"displayName":"Ameni Trabelsi","photoUrl":"","userId":"03261048207976268083"}}},"cell_type":"code","source":["import copy\n","from sklearn import metrics\n","import numpy as np\n","import random\n","\n","with tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as sess:\n","    dropoutList=[0.5,0.75,1.0] #list of possible dropout values\n","    best_AUC=0\n","\n","    for iter in range(10):\n","        sess.run(tf.global_variables_initializer())\n","        sess.run(tf.local_variables_initializer())\n","  \n","                \n","        \n","        prob=random.choice(dropoutList)\n","        \n","        crossV=[0,1,2]\n","    \n","        CV_auc_list=[]\n","        Avg_List=[]\n","        for c in crossV:\n","              \n","              t=copy.copy(crossV)\n","              t.remove(c)\n","              traind=np.concatenate((data[t[0]], data[t[1]]), axis=0)\n","              labeltrain=np.concatenate((label[t[0]], label[t[1]]), axis=0)\n","\n","              testd=data[c]\n","              labeltest=label[c]\n","\n","\n","\n","              avg_cost=0\n","              auc_list=[]\n","              iterationSteps=0\n","              sess.run(iterator.initializer, feed_dict = {x: traind, y: labeltrain})\n","              try:\n","\n","                  while iterationSteps <=20000:\n","                          iterationSteps+=1\n","                      \n","                          ### Training\n","                          _,lss=sess.run([optimizer,loss], feed_dict= {training: 1, dropprob: prob})\n","                         \n","                          \n","                          if iterationSteps % 4000==0:\n","                                  ## Validation\n","\n","                                  sess.run(iterator_val.initializer, feed_dict = {x: testd, y: labeltest})\n","\n","                                  l,yl=sess.run([sigV, data_yV], feed_dict= {training: 0, dropprob: prob})\n","                                  auc=metrics.roc_auc_score(yl, l)\n","                                  print('AUC for the number of iterations',iterationSteps,'is:',auc)\n","                                  auc_list.append(auc)\n","\n","\n","              except tf.errors.OutOfRangeError:\n","                  pass\n","              print('===== Fold Done =====') \n","              CV_auc_list.append(auc_list)\n","              \n","        print('The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps:' , CV_auc_list)\n","        for i in range(len(auc_list)):\n","                Avg_List.append(np.mean([CV_auc_list[j][i] for j in range(len(CV_auc_list))]))\n","        print('The Average AUC for each Iteration Step of The Three Folds is:', Avg_List)\n","        \n","    \n","        \n","        maxlist=max(Avg_List)\n","        if maxlist>best_AUC:\n","          best_AUC=maxlist\n","          \n","          ind=Avg_List.index(maxlist)\n","          \n","          lr,mr,sc,sn,b1,b2,b3 = sess.run([learning_rate, momentum_rate,stdConv, stdNeu,beta1,beta2,beta3], feed_dict= {training: 0, dropprob: prob})\n","          print( 'Best hyperparameters So far:')\n","          print( 'Best Learning Rate', lr)\n","          print( 'Best Momentum Rate', mr)\n","          print( 'Best Learning Step', (ind+1)*4000)\n","          print( 'Best Sigma Conv', sc)\n","          print( 'Best Sigma NN', sn)\n","          print( 'Best Dropout Prob', prob)\n","          print( 'Best Beta 1', b1)\n","          print( 'Best Beta 2', b2)\n","          print( 'Best Beta 3', b3)\n","          \n","          save_LearningRate=lr\n","          save_Momentum=mr\n","          save_LearningStep=(ind+1)*4000\n","          save_SigmaConv=sc\n","          save_SigmaNeu=sn\n","          save_Dropprob=prob\n","          save_Beta1=b1\n","          save_Beta2=b2\n","          save_Beta3=b3\n","          \n","          \n","\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["AUC for the number of iterations 4000 is: 0.9395214806915759\n","AUC for the number of iterations 8000 is: 0.9441221822280585\n","AUC for the number of iterations 12000 is: 0.938926679831435\n","AUC for the number of iterations 16000 is: 0.9429034847422022\n","AUC for the number of iterations 20000 is: 0.9470202601547024\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.9450568772034751\n","AUC for the number of iterations 8000 is: 0.946473613384538\n","AUC for the number of iterations 12000 is: 0.9470491630729035\n","AUC for the number of iterations 16000 is: 0.9434652205049106\n","AUC for the number of iterations 20000 is: 0.9519301754123646\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.9471963419009967\n","AUC for the number of iterations 8000 is: 0.9505986441738596\n","AUC for the number of iterations 12000 is: 0.9498910417816473\n","AUC for the number of iterations 16000 is: 0.9510723888144923\n","AUC for the number of iterations 20000 is: 0.9515916421322737\n","===== Fold Done =====\n","The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.9395214806915759, 0.9441221822280585, 0.938926679831435, 0.9429034847422022, 0.9470202601547024], [0.9450568772034751, 0.946473613384538, 0.9470491630729035, 0.9434652205049106, 0.9519301754123646], [0.9471963419009967, 0.9505986441738596, 0.9498910417816473, 0.9510723888144923, 0.9515916421322737]]\n","The Average AUC for each Iteration Step of The Three Folds is: [0.9439248999320159, 0.947064813262152, 0.9452889615619954, 0.9458136980205349, 0.9501806925664469]\n","Best hyperparameters So far:\n","Best Learning Rate 0.0010576693\n","Best Momentum Rate 0.9787472\n","Best Learning Step 20000\n","Best Sigma Conv 7.850804e-05\n","Best Sigma NN 1.7183995e-05\n","Best Dropout Prob 0.5\n","Best Beta 1 0.00014235532\n","Best Beta 2 7.2569635e-09\n","Best Beta 3 7.581148e-07\n","AUC for the number of iterations 4000 is: 0.5\n","AUC for the number of iterations 8000 is: 0.5\n","AUC for the number of iterations 12000 is: 0.5\n","AUC for the number of iterations 16000 is: 0.5\n","AUC for the number of iterations 20000 is: 0.5\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.5\n","AUC for the number of iterations 8000 is: 0.5\n","AUC for the number of iterations 12000 is: 0.5\n","AUC for the number of iterations 16000 is: 0.5\n","AUC for the number of iterations 20000 is: 0.5\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.5\n","AUC for the number of iterations 8000 is: 0.5\n","AUC for the number of iterations 12000 is: 0.5\n","AUC for the number of iterations 16000 is: 0.5\n","AUC for the number of iterations 20000 is: 0.5\n","===== Fold Done =====\n","The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5]]\n","The Average AUC for each Iteration Step of The Three Folds is: [0.5, 0.5, 0.5, 0.5, 0.5]\n","AUC for the number of iterations 4000 is: 0.9615600476698414\n","AUC for the number of iterations 8000 is: 0.964608817661598\n","AUC for the number of iterations 12000 is: 0.9648276654263949\n","AUC for the number of iterations 16000 is: 0.9649576127418127\n","AUC for the number of iterations 20000 is: 0.9648719189251509\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.964882507554772\n","AUC for the number of iterations 8000 is: 0.9642819621946613\n","AUC for the number of iterations 12000 is: 0.9641133569944598\n","AUC for the number of iterations 16000 is: 0.9639425286451776\n","AUC for the number of iterations 20000 is: 0.9638436476957946\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.9649243567495525\n","AUC for the number of iterations 8000 is: 0.9642419823143072\n","AUC for the number of iterations 12000 is: 0.9639261066550681\n","AUC for the number of iterations 16000 is: 0.9637407475607223\n","AUC for the number of iterations 20000 is: 0.9637202307894812\n","===== Fold Done =====\n","The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.9615600476698414, 0.964608817661598, 0.9648276654263949, 0.9649576127418127, 0.9648719189251509], [0.964882507554772, 0.9642819621946613, 0.9641133569944598, 0.9639425286451776, 0.9638436476957946], [0.9649243567495525, 0.9642419823143072, 0.9639261066550681, 0.9637407475607223, 0.9637202307894812]]\n","The Average AUC for each Iteration Step of The Three Folds is: [0.9637889706580554, 0.9643775873901889, 0.9642890430253076, 0.9642136296492375, 0.9641452658034755]\n","Best hyperparameters So far:\n","Best Learning Rate 0.001694168\n","Best Momentum Rate 0.97135556\n","Best Learning Step 8000\n","Best Sigma Conv 1.7757293e-07\n","Best Sigma NN 0.007921711\n","Best Dropout Prob 1.0\n","Best Beta 1 6.747332e-15\n","Best Beta 2 2.3738276e-09\n","Best Beta 3 3.4559278e-08\n","AUC for the number of iterations 4000 is: 0.954967289493759\n","AUC for the number of iterations 8000 is: 0.9621689144342322\n","AUC for the number of iterations 12000 is: 0.9636781564513741\n","AUC for the number of iterations 16000 is: 0.963786542604473\n","AUC for the number of iterations 20000 is: 0.9638399241865466\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.9665331465625785\n","AUC for the number of iterations 8000 is: 0.9656193044100981\n","AUC for the number of iterations 12000 is: 0.9658203911955427\n","AUC for the number of iterations 16000 is: 0.9663936095284562\n","AUC for the number of iterations 20000 is: 0.9661007440663562\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.9670136250048416\n","AUC for the number of iterations 8000 is: 0.9663800147842712\n","AUC for the number of iterations 12000 is: 0.9658560601162248\n","AUC for the number of iterations 16000 is: 0.9653870364967788\n","AUC for the number of iterations 20000 is: 0.9651807868836814\n","===== Fold Done =====\n","The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.954967289493759, 0.9621689144342322, 0.9636781564513741, 0.963786542604473, 0.9638399241865466], [0.9665331465625785, 0.9656193044100981, 0.9658203911955427, 0.9663936095284562, 0.9661007440663562], [0.9670136250048416, 0.9663800147842712, 0.9658560601162248, 0.9653870364967788, 0.9651807868836814]]\n","The Average AUC for each Iteration Step of The Three Folds is: [0.9628380203537263, 0.9647227445428671, 0.965118202587714, 0.9651890628765694, 0.965040485045528]\n","Best hyperparameters So far:\n","Best Learning Rate 0.0005831973\n","Best Momentum Rate 0.98687667\n","Best Learning Step 16000\n","Best Sigma Conv 2.163379e-07\n","Best Sigma NN 0.00073572644\n","Best Dropout Prob 0.75\n","Best Beta 1 3.498888e-10\n","Best Beta 2 0.00016707329\n","Best Beta 3 3.8914438e-10\n","AUC for the number of iterations 4000 is: 0.9515344121167122\n","AUC for the number of iterations 8000 is: 0.9537695925013111\n","AUC for the number of iterations 12000 is: 0.9562785957128421\n","AUC for the number of iterations 16000 is: 0.9581757124169022\n","AUC for the number of iterations 20000 is: 0.9562974715661681\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.9580074682070008\n","AUC for the number of iterations 8000 is: 0.9585869723463863\n","AUC for the number of iterations 12000 is: 0.9576941615776883\n","AUC for the number of iterations 16000 is: 0.9581359878651473\n","AUC for the number of iterations 20000 is: 0.956205792778897\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.9568972831093527\n","AUC for the number of iterations 8000 is: 0.9566925579926799\n","AUC for the number of iterations 12000 is: 0.9560272480819327\n","AUC for the number of iterations 16000 is: 0.9560428077809275\n","AUC for the number of iterations 20000 is: 0.9562844060401611\n","===== Fold Done =====\n","The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.9515344121167122, 0.9537695925013111, 0.9562785957128421, 0.9581757124169022, 0.9562974715661681], [0.9580074682070008, 0.9585869723463863, 0.9576941615776883, 0.9581359878651473, 0.956205792778897], [0.9568972831093527, 0.9566925579926799, 0.9560272480819327, 0.9560428077809275, 0.9562844060401611]]\n","The Average AUC for each Iteration Step of The Three Folds is: [0.9554797211443553, 0.9563497076134592, 0.9566666684574878, 0.957451502687659, 0.9562625567950754]\n","AUC for the number of iterations 4000 is: 0.9670693967845815\n","AUC for the number of iterations 8000 is: 0.9674708750698057\n","AUC for the number of iterations 12000 is: 0.9679704605781\n","AUC for the number of iterations 16000 is: 0.968646204323607\n","AUC for the number of iterations 20000 is: 0.9696840024772515\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.9713950555590531\n","AUC for the number of iterations 8000 is: 0.97101628407517\n","AUC for the number of iterations 12000 is: 0.9711128533429868\n","AUC for the number of iterations 16000 is: 0.9713152386048856\n","AUC for the number of iterations 20000 is: 0.9716288600163687\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.9720420830254917\n","AUC for the number of iterations 8000 is: 0.9713465585791488\n","AUC for the number of iterations 12000 is: 0.971123155922406\n","AUC for the number of iterations 16000 is: 0.9707331799014561\n","AUC for the number of iterations 20000 is: 0.971011533277721\n","===== Fold Done =====\n","The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.9670693967845815, 0.9674708750698057, 0.9679704605781, 0.968646204323607, 0.9696840024772515], [0.9713950555590531, 0.97101628407517, 0.9711128533429868, 0.9713152386048856, 0.9716288600163687], [0.9720420830254917, 0.9713465585791488, 0.971123155922406, 0.9707331799014561, 0.971011533277721]]\n","The Average AUC for each Iteration Step of The Three Folds is: [0.9701688451230422, 0.9699445725747081, 0.9700688232811642, 0.9702315409433163, 0.9707747985904471]\n","Best hyperparameters So far:\n","Best Learning Rate 0.016331848\n","Best Momentum Rate 0.96831614\n","Best Learning Step 20000\n","Best Sigma Conv 6.3890686e-05\n","Best Sigma NN 0.0026306699\n","Best Dropout Prob 1.0\n","Best Beta 1 3.1816345e-15\n","Best Beta 2 1.0302764e-06\n","Best Beta 3 3.3124023e-05\n","AUC for the number of iterations 4000 is: 0.96760041909706\n","AUC for the number of iterations 8000 is: 0.9669628893641482\n","AUC for the number of iterations 12000 is: 0.9652005200882852\n","AUC for the number of iterations 16000 is: 0.9662712206543189\n","AUC for the number of iterations 20000 is: 0.9653700388252401\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.970397914174641\n","AUC for the number of iterations 8000 is: 0.969022837446487\n","AUC for the number of iterations 12000 is: 0.9682198871505918\n","AUC for the number of iterations 16000 is: 0.9669816914819944\n","AUC for the number of iterations 20000 is: 0.9673404447872073\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.9708985926812881\n","AUC for the number of iterations 8000 is: 0.970156339960657\n","AUC for the number of iterations 12000 is: 0.9700558412221434\n","AUC for the number of iterations 16000 is: 0.9692661127322026\n","AUC for the number of iterations 20000 is: 0.9694355383800434\n","===== Fold Done =====\n","The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.96760041909706, 0.9669628893641482, 0.9652005200882852, 0.9662712206543189, 0.9653700388252401], [0.970397914174641, 0.969022837446487, 0.9682198871505918, 0.9669816914819944, 0.9673404447872073], [0.9708985926812881, 0.970156339960657, 0.9700558412221434, 0.9692661127322026, 0.9694355383800434]]\n","The Average AUC for each Iteration Step of The Three Folds is: [0.9696323086509965, 0.9687140222570975, 0.9678254161536733, 0.9675063416228387, 0.9673820073308302]\n","AUC for the number of iterations 4000 is: 0.9583375194972614\n","AUC for the number of iterations 8000 is: 0.9596651146236439\n","AUC for the number of iterations 12000 is: 0.9604763336833022\n","AUC for the number of iterations 16000 is: 0.960458608676688\n","AUC for the number of iterations 20000 is: 0.960355602977872\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.962568720882649\n","AUC for the number of iterations 8000 is: 0.9615152531635609\n","AUC for the number of iterations 12000 is: 0.9618943492665576\n","AUC for the number of iterations 16000 is: 0.9624480412679426\n","AUC for the number of iterations 20000 is: 0.9620707059777134\n","===== Fold Done =====\n","AUC for the number of iterations 4000 is: 0.9599055964932569\n","AUC for the number of iterations 8000 is: 0.9597974457662364\n","AUC for the number of iterations 12000 is: 0.9591483643658186\n","AUC for the number of iterations 16000 is: 0.9594357270241816\n","AUC for the number of iterations 20000 is: 0.9596889016207837\n","===== Fold Done =====\n","The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.9583375194972614, 0.9596651146236439, 0.9604763336833022, 0.960458608676688, 0.960355602977872], [0.962568720882649, 0.9615152531635609, 0.9618943492665576, 0.9624480412679426, 0.9620707059777134], [0.9599055964932569, 0.9597974457662364, 0.9591483643658186, 0.9594357270241816, 0.9596889016207837]]\n","The Average AUC for each Iteration Step of The Three Folds is: [0.9602706122910557, 0.9603259378511471, 0.9605063491052261, 0.9607807923229373, 0.960705070192123]\n","AUC for the number of iterations 4000 is: 0.9663045066822783\n","AUC for the number of iterations 8000 is: 0.9665780737654971\n","AUC for the number of iterations 12000 is: 0.96619099581861\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-89751f59311d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                           \u001b[0;31m### Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropprob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"XZK-IaoTkYBK","colab_type":"code","colab":{}},"cell_type":"code","source":["graph2=tf.Graph()\n","with graph2.as_default():\n","    \n","    num_input_channels=4\n","    num_filters=16\n","    filter_shape=24\n","    pooling='max_pool'\n","    neuType='hidden'\n","    \n","    beta1=save_Beta1\n","    beta2=save_Beta2\n","    beta3=save_Beta3\n","\n","    \n","    \n","    learning_rate= save_LearningRate\n","    momentum_rate= save_Momentum\n","    batch_size=64\n","    \n","    \n","    with tf.device('/gpu:0'):\n","    \n","      x = tf.placeholder(tf.float32, [None, 147, 4],name='X')\n","      y = tf.placeholder(tf.float32,[None,1],name='y')\n","\n","\n","    with tf.device('/cpu:0'):\n","      \n","      #Set up iterator for the data\n","      dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","      dataset = dataset.shuffle(500).repeat().batch(batch_size)\n","      iterator = dataset.make_initializable_iterator()\n","      data_X, data_y = iterator.get_next()\n","      data_y = tf.cast(data_y, tf.float32)\n","\n","      dropprob = tf.placeholder_with_default(0.5, shape=(),name='prob')\n","\n","      # Distinguish training and testing: training=1 for training , =0 for testing\n","      training = tf.placeholder_with_default(0.0, shape=(),name='training')\n","      \n","   \n","    with tf.device('/gpu:0'):\n","      \n","      conv_filt_shape = [filter_shape, num_input_channels, num_filters]\n","\n","      stdConv=save_SigmaConv\n","      # initialise weights and bias for the filter\n","      conv_weights = tf.Variable(tf.truncated_normal(conv_filt_shape, mean=0,stddev=stdConv), name='Conv1_W')\n","      conv_bias = tf.Variable(tf.truncated_normal([num_filters]), name='Conv1_b')\n","\n","\n","\n","      if pooling=='max_pool':\n","          W = tf.Variable(tf.truncated_normal([16,32], mean=0, stddev=0.3), name='W')\n","          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')\n","      else:\n","          W = tf.Variable(tf.truncated_normal([32,32], mean=0, stddev=0.3), name='W')\n","          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')     \n","\n","      if neuType == 'nohidden':\n","          if pooling=='max_pool':\n","              wdim1=16\n","          else:\n","              wdim1=32\n","      else:\n","          wdim1=32\n","      stdNeu=save_SigmaNeu\n","      wd1 = tf.Variable(tf.truncated_normal([wdim1,1], mean=0, stddev=stdNeu), name='w2')\n","      bd1 = tf.Variable(tf.truncated_normal([1], mean=0, stddev=stdNeu), name='b2')\n","\n","\n","      xconv = convolution(data_X,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n","\n","      sig = tf.nn.sigmoid(xconv)\n","      if neuType == 'hidden':\n","        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)+ beta3*tf.norm(W,ord=1)\n","      else:\n","        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)\n","  #     loss=tf.reduce_mean(-1*tf.losses.log_loss(sig,data_y))\n","\n","      #optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n","      optimizer=tf.train.MomentumOptimizer(learning_rate,momentum_rate,use_nesterov=True).minimize(loss)\n","    with tf.device('/cpu:0'):\n","      \n","      #Set up iterator for the validation data\n","      dataset_val = tf.data.Dataset.from_tensor_slices((x, y))\n","      dataset_val = dataset_val.batch(tf.cast(tf.size(y),tf.int64))\n","                  \n","      iterator_val = dataset_val.make_initializable_iterator()\n","      data_XV, data_yV = iterator_val.get_next()      \n","      data_yV = tf.cast(data_yV, tf.float32)\n","      \n","      \n","      data_XV = tf.placeholder_with_default(data_XV, shape=None, name='input')\n","      data_yV = tf.placeholder_with_default(data_yV, shape=None,name='label')\n","      \n","      \n","    with tf.device('/gpu:0'):\n","      xconvV = convolution(data_XV,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n","\n","      sigV = tf.nn.sigmoid(xconvV, name='Conv_V')\n","  \n","    saver = tf.train.Saver()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"huj8k7YtXGXu","colab_type":"code","colab":{}},"cell_type":"code","source":["import copy\n","from sklearn import metrics\n","import numpy as np\n","import random\n","\n","\n","\n","with tf.Session(graph=graph2, config=tf.ConfigProto(log_device_placement=True)) as sess:\n","    auc_list=[]\n","    best_auc=0\n","    for iter in range(6):\n","        sess.run(tf.global_variables_initializer())\n","        sess.run(tf.local_variables_initializer())\n","        \n","\n","        prob=save_Dropprob\n","        iterationSteps=0\n","        sess.run(iterator.initializer, feed_dict = {x: data_all, y: label_all})\n","        try:\n","\n","            while iterationSteps <=save_LearningStep:\n","                  iterationSteps+=1\n","              \n","                  ### Training\n","                  _,lss=sess.run([optimizer,loss], feed_dict= {training: 1, dropprob: prob})\n","                  \n","        except tf.errors.OutOfRangeError:\n","            pass\n","          \n","        ## Validation\n","        sess.run(iterator_val.initializer, feed_dict = {x: data_all, y: label_all})\n","        l,yl=sess.run([sigV,data_yV], feed_dict= {training: 0, dropprob: prob})\n","\n","        auc=metrics.roc_auc_score(yl, l)\n","        print('AUC of Model Num',iter,' is : ', auc)\n","        \n","        if auc > best_auc:\n","          best_auc=auc\n","          print('Best AUC So Far is : ', best_auc)\n","          ##save model\n","          save_path = saver.save(sess, \"/content/drive/My Drive/Colab Notebooks/Test/model\")\n","          print('Model Saved!')\n","\n","          \n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"P4ES6bgYBbKh","colab_type":"code","colab":{}},"cell_type":"code","source":["import copy\n","from sklearn import metrics\n","import numpy as np\n","import random"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8vr5DH5ER0k2","colab_type":"code","colab":{}},"cell_type":"code","source":["filename='/content/drive/My Drive/Colab Notebooks/Chip-seq/USF1_HepG2_USF-1_HudsonAlpha_AC.seq.gz'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5cRQzE9-YsAd","colab_type":"code","colab":{}},"cell_type":"code","source":["class ChipTest(Experiment):\n","    def __init__(self,filename,motiflen=24):\n","        self.file = filename\n","        self.motiflen = motiflen\n","            \n","    def openFile(self):\n","        train_dataset=[]\n","     \n","        with gzip.open(self.file, 'rt') as data:\n","            next(data)\n","            reader = csv.reader(data,delimiter='\\t')\n","            \n","            for row in reader:\n","                    train_dataset.append([seqtopad(row[2],self.motiflen),[row[3]]])\n","                    \n","                   \n","        \n","\n","        return train_dataset"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WbQxI6v4R2cb","colab_type":"code","colab":{}},"cell_type":"code","source":["test= ChipTest(filename)\n","dataAll =test.openFile()\n","data_all=np.asarray([el[0] for el in dataAll],dtype=np.float32)\n","label_all=np.asarray([el[1] for el in dataAll],dtype=np.float32).reshape(len(data_all),1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zO0bp4gHxTWw","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","\n","graphF=tf.Graph()\n","with tf.Session(graph=graphF) as sess:    \n","  \n","  # #First let's load meta graph and restore weights\n","  ckpt = tf.train.get_checkpoint_state('/content/drive/My Drive/Colab Notebooks/Test', latest_filename='checkpoint')\n","  \n","  if ckpt and ckpt.model_checkpoint_path:  # if there's checkpoint\n","    saver = tf.train.import_meta_graph('/content/drive/My Drive/Colab Notebooks/Test/model.meta')\n","    saver.restore(sess, ckpt.model_checkpoint_path)\n","\n","    \n","    # graph = tf.get_default_graph()\n","    X = graphF.get_tensor_by_name(\"input:0\")\n","    y = graphF.get_tensor_by_name(\"label:0\")\n","\n","\n","    training = graphF.get_tensor_by_name(\"training:0\")\n","    prob = graphF.get_tensor_by_name(\"prob:0\")\n","#     feed_dict ={X:data_all,y:label_all}\n","#     print(sess.run(W))\n","    # #Now, access the op that you want to run. \n","    Conv_V = graphF.get_tensor_by_name(\"Conv_V:0\")\n","#     sess.run(iterator_val.initializer, feed_dict)\n","    feed_dict2={X:data_all,y:label_all,prob:save_Dropprob}\n","    l=sess.run(Conv_V,feed_dict2)\n","    auc=metrics.roc_auc_score(label_all, l)\n","    print(auc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-FVFwdZoNwxS","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}